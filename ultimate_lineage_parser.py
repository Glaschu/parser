import re
import sqlparse
from sqllineage.runner import LineageRunner
from collections import defaultdict, OrderedDict

def extract_table_name(table_str):
    """Extract clean table name from various formats"""
    if not table_str:
        return "unknown"
    
    # Remove schema prefixes and clean up
    table_str = str(table_str).lower()
    if '.' in table_str:
        parts = table_str.split('.')
        return parts[-1]  # Take the table name part
    return table_str

def categorize_table(table_name):
    """Categorize tables into source, intermediate, or target"""
    table_name = table_name.lower()
    
    if any(pattern in table_name for pattern in ['staging', 'ref']):
        return 'source'
    elif any(pattern in table_name for pattern in ['#', 'temp', 'work', 'stage', 'valid', 'invalid', 'fees', 'post', 'bal', 'scores']):
        return 'intermediate'
    elif any(pattern in table_name for pattern in ['core', 'audit', 'ops']):
        return 'target'
    else:
        return 'other'

def create_end_to_end_lineage_report():
    """Create the ultimate end-to-end lineage report"""
    
    # Read the SQL file
    with open("test.sql", "r") as f:
        sql = f.read()

    print("üîç " + "=" * 98)
    print("   ULTIMATE END-TO-END SQL LINEAGE ANALYSIS")
    print("   Banking Settlement Procedure: usp_ProcessDailyCoreBankingSettlement_Monster")
    print("=" * 100)

    # Extract procedure body
    sql_body = re.search(r"AS\s*BEGIN(.*)END\s*GO", sql, re.DOTALL | re.IGNORECASE)
    if sql_body:
        sql = sql_body.group(1)

    # Find all DML statements
    statements = sqlparse.split(sql)
    dml_statements = []
    
    for stmt_str in statements:
        if stmt_str.strip():
            parsed_stmt = sqlparse.parse(stmt_str)[0]
            stmt_type = parsed_stmt.get_type()
            first_token = parsed_stmt.tokens[0].normalized if parsed_stmt.tokens else ""
            
            if stmt_type in ["INSERT", "UPDATE", "MERGE"] or first_token == 'WITH':
                dml_statements.append(stmt_str)

    # Analyze lineage
    all_tables = {
        'source': set(),
        'intermediate': set(), 
        'target': set(),
        'other': set()
    }
    
    table_flow = defaultdict(set)  # source -> targets
    column_flows = []
    processing_stages = []

    print(f"üìä Processing {len(dml_statements)} DML statements...")
    
    for i, stmt in enumerate(dml_statements):
        try:
            clean_stmt = re.sub(r"@[a-zA-Z_]+", "'sample_value'", stmt)
            result = LineageRunner(clean_stmt, dialect="tsql")
            
            source_tables = result.source_tables
            target_tables = result.target_tables
            intermediate_tables = result.intermediate_tables
            column_lineage = result.get_column_lineage()
            
            # Categorize and track tables
            stage_sources = []
            stage_targets = []
            stage_intermediates = []
            
            for table in source_tables:
                table_name = extract_table_name(table)
                category = categorize_table(table_name)
                all_tables[category].add(table_name)
                stage_sources.append(table_name)
            
            for table in target_tables:
                table_name = extract_table_name(table)
                category = categorize_table(table_name)
                all_tables[category].add(table_name)
                stage_targets.append(table_name)
            
            for table in intermediate_tables:
                table_name = extract_table_name(table)
                all_tables['intermediate'].add(table_name)
                stage_intermediates.append(table_name)
            
            # Record stage
            processing_stages.append({
                'stage': i + 1,
                'sources': stage_sources,
                'targets': stage_targets,
                'intermediates': stage_intermediates,
                'columns': len(column_lineage)
            })
            
            # Track flows
            for source in source_tables:
                source_name = extract_table_name(source)
                for target in target_tables:
                    target_name = extract_table_name(target)
                    table_flow[source_name].add(target_name)
            
            # Track column flows
            for mapping in column_lineage:
                if mapping and len(mapping) >= 2:
                    source_col = str(mapping[0]) if mapping[0] else 'unknown'
                    target_col = str(mapping[-1]) if mapping[-1] else 'unknown'
                    column_flows.append((source_col, target_col, i+1))
                    
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Stage {i+1}: Processing error - {str(e)[:50]}...")

    # REPORT GENERATION
    print("\nüéØ " + "=" * 98)
    print("   BUSINESS DATA FLOW OVERVIEW")
    print("=" * 100)
    
    print("üì• SOURCE SYSTEMS:")
    source_list = sorted(all_tables['source'])
    if source_list:
        for i, table in enumerate(source_list, 1):
            targets = sorted(table_flow.get(table, set()))
            print(f"   {i:2d}. {table:<30} ‚Üí {', '.join(targets[:3])}")
            if len(targets) > 3:
                print(f"       {'':<30}   (+ {len(targets)-3} more targets)")
    else:
        print("   No direct source tables identified")

    print(f"\nüîÑ PROCESSING LAYERS:")
    intermediate_list = sorted(all_tables['intermediate'])
    if intermediate_list:
        temp_tables = [t for t in intermediate_list if t.startswith('#')]
        other_intermediate = [t for t in intermediate_list if not t.startswith('#')]
        
        if temp_tables:
            print(f"   Temporary Tables: {', '.join(temp_tables)}")
        if other_intermediate:
            print(f"   Work/Stage Tables: {', '.join(other_intermediate)}")
    else:
        print("   No intermediate processing layers identified")

    print(f"\nüì§ TARGET SYSTEMS:")
    target_list = sorted(all_tables['target'])
    if target_list:
        # Group by schema/system
        core_tables = [t for t in target_list if 'core' in t]
        audit_tables = [t for t in target_list if 'audit' in t]
        ops_tables = [t for t in target_list if 'ops' in t]
        
        if core_tables:
            print(f"   Core Banking: {', '.join(core_tables)}")
        if audit_tables:
            print(f"   Audit/Logging: {', '.join(audit_tables)}")
        if ops_tables:
            print(f"   Operations: {', '.join(ops_tables)}")
    else:
        print("   No target systems identified")

    print("\nüîç " + "=" * 98)
    print("   DETAILED PROCESSING PIPELINE")
    print("=" * 100)
    
    # Show key stages
    key_stages = []
    for stage in processing_stages:
        if stage['columns'] > 5 or any('staging' in s for s in stage['sources']) or any('core' in t for t in stage['targets']):
            key_stages.append(stage)
    
    print(f"{'Stage':<6} {'Description':<50} {'Columns'}")
    print("-" * 100)
    
    for stage in key_stages[:15]:  # Show first 15 key stages
        sources = stage['sources'][:2]
        targets = stage['targets'][:2]
        
        if any('staging' in s for s in sources):
            desc = f"Data ingestion from {', '.join(sources)}"
        elif any('#' in t for t in targets):
            desc = f"Processing into temp tables: {', '.join(targets)}"
        elif any('core' in t for t in targets):
            desc = f"Final persistence to {', '.join(targets)}"
        elif any('audit' in t for t in targets):
            desc = f"Audit logging to {', '.join(targets)}"
        else:
            desc = f"{', '.join(sources)} ‚Üí {', '.join(targets)}"
        
        if len(desc) > 48:
            desc = desc[:45] + "..."
            
        print(f"{stage['stage']:<6} {desc:<50} {stage['columns']}")

    print("\nüéØ " + "=" * 98)
    print("   END-TO-END SOURCE-TO-TARGET MAPPING")
    print("=" * 100)
    
    # Build source-to-target mapping by following the flow
    def find_final_targets(table_name, visited=None):
        if visited is None:
            visited = set()
        if table_name in visited:
            return set()
        visited.add(table_name)
        
        targets = table_flow.get(table_name, set())
        final_targets = set()
        
        for target in targets:
            target_category = categorize_table(target)
            if target_category == 'target':
                final_targets.add(target)
            elif target_category in ['intermediate', 'other']:
                final_targets.update(find_final_targets(target, visited.copy()))
        
        return final_targets

    print(f"{'Source System':<30} {'Final Destination(s)':<40} {'Data Purpose'}")
    print("-" * 100)
    
    for source in sorted(all_tables['source']):
        final_targets = find_final_targets(source)
        if final_targets:
            targets_str = ', '.join(sorted(final_targets))
            if len(targets_str) > 38:
                targets_str = targets_str[:35] + "..."
            
            # Determine purpose
            if any('ledger' in t for t in final_targets):
                purpose = "Financial Ledger"
            elif any('gl' in t for t in final_targets):
                purpose = "General Ledger"
            elif any('audit' in t for t in final_targets):
                purpose = "Audit Trail"
            elif any('ops' in t for t in final_targets):
                purpose = "Operations"
            else:
                purpose = "Core Banking"
                
            print(f"{source:<30} {targets_str:<40} {purpose}")
        else:
            print(f"{source:<30} {'(intermediate processing only)':<40} {'Data Staging'}")

    print("\nüìà " + "=" * 98)
    print("   SUMMARY STATISTICS")
    print("=" * 100)
    
    total_sources = len(all_tables['source'])
    total_intermediates = len(all_tables['intermediate'])
    total_targets = len(all_tables['target'])
    total_columns = sum(stage['columns'] for stage in processing_stages)
    
    print(f"   üìä Processing Overview:")
    print(f"      ‚Ä¢ Source tables: {total_sources}")
    print(f"      ‚Ä¢ Processing layers: {total_intermediates}")
    print(f"      ‚Ä¢ Target systems: {total_targets}")
    print(f"      ‚Ä¢ Total column transformations: {total_columns}")
    print(f"      ‚Ä¢ Processing stages: {len(processing_stages)}")
    
    print(f"\n   üéØ Business Process:")
    print(f"      ‚Ä¢ Daily settlement batch processing")
    print(f"      ‚Ä¢ Multi-stage data validation and enrichment")
    print(f"      ‚Ä¢ Fee calculation and risk assessment")
    print(f"      ‚Ä¢ Dual-entry bookkeeping (ledger + GL)")
    print(f"      ‚Ä¢ Comprehensive audit and reconciliation")

    print("\n" + "=" * 100)
    print("‚úÖ ANALYSIS COMPLETE - End-to-end lineage mapping successful!")
    print("=" * 100)

if __name__ == "__main__":
    create_end_to_end_lineage_report()
